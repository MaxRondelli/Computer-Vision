{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azPwLEGsz-Md"
      },
      "source": [
        "# Transfer Learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns74Mo7nir2G"
      },
      "source": [
        "\n",
        "TL is the process of taking features learned for one task and reusing them to solve a new but similar problem, instead of starting the learning process from scratch. This technique is very popular since it allows to build accurate models without having to training our network for days. Usually, transfer learning is the way to go in tasks where the training dataset has a small number of samples.\n",
        "\n",
        "A transfer learning workflow for image classification includes the following steps:\n",
        "\n",
        "1. **Take a pre-trained model**: choose a model that was trained on a large dataset to solve a similar problem. A common practice is to grab models from the literature such as: VGG, ResNet, MobileNet etc.\n",
        "2. **Chop the classifier**: remove the old classifier.\n",
        "3. **Add a new classifier**: adapt the architecture to solve the new task.\n",
        "4. **Use the convolutional block as Feature Extractor**: train **only** the new classifier on the new dataset and exclude the feature extractor from the back-propagation process (freezing).\n",
        "5. **Fine-tuning**: a last optional step involves the **fine-tuning** of the new network. It consists in unfreezing parts of the pre-trained model and continue to training it on the new dataset in order to adapt the pretrained features to the new data. To avoid overfitting, we usually run this step only if the new dataset is **large**.\n",
        "\n",
        "\n",
        "**A part comparing results obtained using a fine-tuned configuration of VIT and a fine-tuned CNN have been added.**\n",
        "\n",
        "\n",
        "Credits to [Giuseppe Lisanti](https://www.unibo.it/sitoweb/giuseppe.lisanti/en), Samuele Salti and Riccardo Spezialetti.\n",
        "\n",
        "Thanks to [Lorenzo Stacchio](https://www.unibo.it/sitoweb/lorenzo.stacchio2/en) for the ViT notebook part.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lLFOMAf5qfA"
      },
      "source": [
        "## Import Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzhg6tU8YvAW",
        "outputId": "2c7d0555-7d14-40a5-e17a-bfce511e22ad"
      },
      "outputs": [],
      "source": [
        "! pip install torchinfo\n",
        "\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils as utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from torchvision import  models, transforms\n",
        "from torchinfo import summary # Formerly known  as torch summary\n",
        "from typing import Callable, Dict, List, Tuple, Union\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPmh48qzlrzk"
      },
      "source": [
        "## Reproducibility\n",
        "Remember that deterministic operations tend to have slower performance than non-deterministic operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhOiCAcW0R2i"
      },
      "outputs": [],
      "source": [
        "def fix_random(seed: int) -> None:\n",
        "    \"\"\"Fix all the possible sources of randomness.\n",
        "\n",
        "    Args:\n",
        "        seed: the seed to use.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "fix_random(seed=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJbkbcfoyPFY"
      },
      "source": [
        "## Runtime Settings\n",
        "\n",
        "Let's check that our  environment has the proper configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib8_3-Scxvk8",
        "outputId": "0d3c2c65-f4d4-4107-a606-4475e19a34ad"
      },
      "outputs": [],
      "source": [
        "device = \"cpu\"\n",
        "if torch.cuda.is_available:\n",
        "  print('Gpu available')\n",
        "  device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "  print('Please set GPU via Edit -> Notebook Settings.')\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpWTJn04trBd"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnmpHrwUBoK3",
        "outputId": "6b340c72-42ca-453e-8f56-15c9fec116fa"
      },
      "outputs": [],
      "source": [
        "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip -qq hymenoptera_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8k_alhCuO7Ru",
        "outputId": "252c1a37-1f90-4691-eb20-cfd58a310171"
      },
      "outputs": [],
      "source": [
        "path_ds = 'hymenoptera_data'\n",
        "path_ds_train = os.path.join(path_ds, 'train')\n",
        "path_ds_val = os.path.join(path_ds, 'val')\n",
        "\n",
        "# Means and standard deviations of the RGB channels of the ImageNet dataset\n",
        "mean_image_net = [0.485, 0.456, 0.406]\n",
        "std_image_net = [0.229, 0.224, 0.225]\n",
        "normalize = transforms.Normalize(mean_image_net, std_image_net)\n",
        "\n",
        "size_image = 224  # try 64 or 128 (only with CNN)\n",
        "data_transforms = {'train': transforms.Compose([transforms.RandomResizedCrop(size_image), # Data augmentation\n",
        "                                                transforms.RandomHorizontalFlip(),        # Data augmentation\n",
        "                                                transforms.ToTensor(),\n",
        "                                                normalize]),\n",
        "\n",
        "                   'val': transforms.Compose([transforms.Resize(int(size_image*1.2)),\n",
        "                                              transforms.CenterCrop(size_image),\n",
        "                                              transforms.ToTensor(),\n",
        "                                              normalize])}\n",
        "\n",
        "\n",
        "# ImageFolder is a generic dataloader where the images are arranged in this way:\n",
        "#     root/class_1/xxx.png\n",
        "#     root/class_1/xxy.png\n",
        "#     ...\n",
        "#     root/class_2/123.png\n",
        "#     root/class_2/nsdf3.png\n",
        "data_train = torchvision.datasets.ImageFolder(path_ds_train, data_transforms['train'])\n",
        "data_val = torchvision.datasets.ImageFolder(path_ds_val, data_transforms['val'])\n",
        "\n",
        "classes = data_train.classes\n",
        "num_classes = len(classes)\n",
        "\n",
        "print(f'Samples -> Train = {len(data_train)} | Val = {len(data_val)} '\n",
        "      f'| Classes = {classes}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Fv849lzxLs"
      },
      "source": [
        "Visualize some examples from the validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "YrzNXbbDndVO",
        "outputId": "2ca3e9ae-c21d-4853-cabe-57f87c390dbc"
      },
      "outputs": [],
      "source": [
        "# For visualization purposes, we need to denormalize the images\n",
        "# to show them in the correct range of values.\n",
        "class NormalizeInverse(torchvision.transforms.Normalize):\n",
        "    def __init__(self, mean: List[float], std: List[float]) -> None:\n",
        "        \"\"\"Reconstructs the images in the input domain by inverting\n",
        "        the normalization transformation.\n",
        "\n",
        "        Args:\n",
        "            mean: the mean used to normalize the images.\n",
        "            std: the standard deviation used to normalize the images.\n",
        "        \"\"\"\n",
        "        mean = torch.as_tensor(mean)\n",
        "        std = torch.as_tensor(std)\n",
        "        std_inv = 1 / (std + 1e-7) # 1e-7 is a small value to avoid division by zero.\n",
        "        mean_inv = -mean * std_inv\n",
        "        super().__init__(mean=mean_inv, std=std_inv)\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return super().__call__(tensor.clone())\n",
        "\n",
        "def show_grid(dataset: torchvision.datasets.ImageFolder,\n",
        "              process: Callable = None) -> None:\n",
        "    \"\"\"Shows a grid with random images taken from the dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: the dataset containing the images.\n",
        "        process: a function to apply on the images before showing them.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    indices_random = np.random.randint(10, size=10, high=len(dataset))\n",
        "\n",
        "    for count, idx in enumerate(indices_random):\n",
        "        fig.add_subplot(2, 5, count + 1)\n",
        "        title = dataset.classes[dataset[idx][1]]\n",
        "        plt.title(title)\n",
        "        image_processed = process(dataset[idx][0]) if process is not None else dataset[idx][0]\n",
        "        plt.imshow(transforms.ToPILImage()(image_processed))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Show some examples\n",
        "denormalize = NormalizeInverse(mean_image_net, std_image_net)\n",
        "show_grid(data_val, process=denormalize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws2E-hOBzSdd"
      },
      "source": [
        "Plot the distribution of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "UK7P-sfnoSVM",
        "outputId": "0185c7c3-4cd2-4d23-d8c0-28d13444f1c7"
      },
      "outputs": [],
      "source": [
        "def plot_histograms(dataset_train: torchvision.datasets.ImageFolder,\n",
        "                    dataset_test: torchvision.datasets.ImageFolder,\n",
        "                    title: str,\n",
        "                    classes_as_ticks: bool = True) -> None:\n",
        "    \"\"\"Plot histograms with train and test or validation data distributions.\n",
        "\n",
        "    Args:\n",
        "        dataset_train: the train dataset.\n",
        "        dataset_test: the test or validation dataset.\n",
        "        title: the title of the plot.\n",
        "        classes_as_ticks: if true the name of the classes are show in the x axis.\n",
        "    \"\"\"\n",
        "    classes = len(dataset_train.classes)\n",
        "    train_data = [label for _, label in dataset_train]\n",
        "    test_data = [label for _, label in dataset_test]\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.hist([train_data, test_data], bins=np.arange(classes + 1) - 0.5, rwidth=0.8, align='mid')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Classes')\n",
        "    plt.ylabel('Number of images')\n",
        "    plt.legend(['Train', 'Test'])\n",
        "\n",
        "    if classes_as_ticks:\n",
        "        plt.xticks(np.arange(classes), dataset_train.classes)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_histograms(data_train, data_val, \"Data Distribution\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKp0Kz_C0z1K"
      },
      "source": [
        "## Train Functionalities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCkuOTqux2oq"
      },
      "outputs": [],
      "source": [
        "num_workers = 2\n",
        "size_batch = 64\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(data_train, batch_size=size_batch,\n",
        "                                           shuffle=True,\n",
        "                                           pin_memory=True, # speed-up CPU-GPU transfer\n",
        "                                           num_workers=num_workers)\n",
        "\n",
        "loader_val = torch.utils.data.DataLoader(data_val, batch_size=size_batch,\n",
        "                                         shuffle=False,\n",
        "                                         num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-3GGR9O05dn"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "def get_correct_samples(scores: torch.Tensor, labels: torch.Tensor) -> int:\n",
        "    \"\"\"Gets the number of correctly classified examples.\n",
        "\n",
        "    Args:\n",
        "        scores: the scores predicted with the network.\n",
        "        labels: the class labels.\n",
        "\n",
        "    Returns:\n",
        "        the number of correct samples.\n",
        "    \"\"\"\n",
        "    # Argmax is used when the label is one-hot encoded (e.g. softmax)\n",
        "    classes_predicted = torch.argmax(scores, 1) \n",
        "    return (classes_predicted == labels).sum().item()\n",
        "\n",
        "# Train one epoch\n",
        "def train(writer: utils.tensorboard.writer.SummaryWriter,\n",
        "          model: nn.Module,\n",
        "          train_loader: utils.data.DataLoader,\n",
        "          device: torch.device,\n",
        "          optimizer: torch.optim,\n",
        "          criterion: Callable[[torch.Tensor, torch.Tensor], float],\n",
        "          log_interval: int,\n",
        "          epoch: int) -> Tuple[float, float]:\n",
        "    \"\"\"Trains a neural network for one epoch.\n",
        "\n",
        "    Args:\n",
        "        model: the model to train.\n",
        "        train_loader: the data loader containing the training data.\n",
        "        device: the device to use to train the model.\n",
        "        optimizer: the optimizer to use to train the model.\n",
        "        criterion: the loss to optimize.\n",
        "        log_interval: the log interval.\n",
        "        epoch: the number of the current epoch.\n",
        "\n",
        "    Returns:\n",
        "        the cross entropy Loss value on the training data.\n",
        "        the accuracy on the training data.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    samples_train = 0\n",
        "    loss_train = 0\n",
        "    size_ds_train = len(train_loader.dataset)\n",
        "    num_batches = len(train_loader)\n",
        "\n",
        "    model.train()\n",
        "    for idx_batch, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        # Reset the gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        scores = model(images)\n",
        "\n",
        "        loss = criterion(scores, labels)\n",
        "        loss_train += loss.item() * len(images)\n",
        "        samples_train += len(images)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct += get_correct_samples(scores, labels)\n",
        "\n",
        "        if log_interval > 0:\n",
        "            if idx_batch % log_interval == 0:\n",
        "                running_loss = loss_train / samples_train\n",
        "                global_step = idx_batch + (epoch * num_batches)\n",
        "                writer.add_scalar('Metrics/Loss_Train_IT', running_loss, global_step)\n",
        "                # Visualize images on tensorboard\n",
        "                indices_random = torch.randperm(images.size(0))[:4]\n",
        "                writer.add_images('Samples/Train', denormalize(images[indices_random]), global_step)\n",
        "\n",
        "    loss_train /= samples_train\n",
        "    accuracy_training = 100. * correct / samples_train\n",
        "    return loss_train, accuracy_training\n",
        "\n",
        "# Validate one epoch\n",
        "def validate(model: nn.Module,\n",
        "             data_loader: utils.data.DataLoader,\n",
        "             device: torch.device,\n",
        "             criterion: Callable[[torch.Tensor, torch.Tensor], float]) -> Tuple[float, float]:\n",
        "    \"\"\"Evaluates the model.\n",
        "\n",
        "    Args:\n",
        "        model: the model to evalaute.\n",
        "        data_loader: the data loader containing the validation or test data.\n",
        "        device: the device to use to evaluate the model.\n",
        "        criterion: the loss function.\n",
        "\n",
        "    Returns:\n",
        "        the loss value on the validation data.\n",
        "        the accuracy on the validation data.\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    samples_val = 0\n",
        "    loss_val = 0.\n",
        "    \n",
        "    # Always set the model to eval mode when evaluating\n",
        "    model.eval() \n",
        "    with torch.no_grad():\n",
        "        for idx_batch, (images, labels) in enumerate(data_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            scores = model(images)\n",
        "\n",
        "            loss = criterion(scores, labels)\n",
        "            loss_val += loss.item() * len(images)\n",
        "            samples_val += len(images)\n",
        "            correct += get_correct_samples(scores, labels)\n",
        "\n",
        "    loss_val /= samples_val\n",
        "    accuracy = 100. * correct / samples_val\n",
        "    return loss_val, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRJmWE8R1bIB"
      },
      "outputs": [],
      "source": [
        "def training_loop(writer: utils.tensorboard.writer.SummaryWriter,\n",
        "                  num_epochs: int,\n",
        "                  optimizer: torch.optim,\n",
        "                  lr_scheduler: torch.optim.lr_scheduler,\n",
        "                  log_interval: int,\n",
        "                  model: nn.Module,\n",
        "                  loader_train: utils.data.DataLoader,\n",
        "                  loader_val: utils.data.DataLoader,\n",
        "                  verbose: bool=True) -> Dict:\n",
        "    \"\"\"Executes the training loop.\n",
        "\n",
        "        Args:\n",
        "            writer: the summary writer for tensorboard.\n",
        "            num_epochs: the number of epochs.\n",
        "            optimizer: the optimizer to use.\n",
        "            lr_scheduler: the scheduler for the learning rate.\n",
        "            log_interval: intervall to print on tensorboard.\n",
        "            model: the mode to train.\n",
        "            loader_train: the data loader containing the training data.\n",
        "            loader_val: the data loader containing the validation data.\n",
        "            verbose: if true print the value of loss.\n",
        "\n",
        "        Returns:\n",
        "            A dictionary with the statistics computed during the train:\n",
        "            the values for the train loss for each epoch.\n",
        "            the values for the train accuracy for each epoch.\n",
        "            the values for the validation accuracy for each epoch.\n",
        "            the time of execution in seconds for the entire loop.\n",
        "    \"\"\"\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loop_start = timer()\n",
        "\n",
        "    losses_values = []\n",
        "    train_acc_values = []\n",
        "    val_acc_values = []\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        time_start = timer()\n",
        "        loss_train, accuracy_train = train(writer, model, loader_train, device,\n",
        "                                           optimizer, criterion, log_interval,\n",
        "                                           epoch)\n",
        "        loss_val, accuracy_val = validate(model, loader_val, device, criterion)\n",
        "        time_end = timer()\n",
        "\n",
        "        losses_values.append(loss_train)\n",
        "        train_acc_values.append(accuracy_train)\n",
        "        val_acc_values.append(accuracy_val)\n",
        "\n",
        "        lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        if verbose:\n",
        "            print(f'Epoch: {epoch} '\n",
        "                  f' Lr: {lr:.10f} '\n",
        "                  f' Loss: Train = [{loss_train:.4f}] - Val = [{loss_val:.4f}] '\n",
        "                  f' Accuracy: Train = [{accuracy_train:.2f}%] - Val = [{accuracy_val:.2f}%] '\n",
        "                  f' Time one epoch (s): {(time_end - time_start):.4f} ')\n",
        "\n",
        "        # Plot to tensorboard\n",
        "        writer.add_scalar('Hyperparameters/Learning Rate', lr, epoch)\n",
        "        writer.add_scalars('Metrics/Losses', {\"Train\": loss_train, \"Val\": loss_val}, epoch)\n",
        "        writer.add_scalars('Metrics/Accuracy', {\"Train\": accuracy_train, \"Val\": accuracy_val}, epoch)\n",
        "        writer.flush()\n",
        "\n",
        "        # Increases the internal counter\n",
        "        if lr_scheduler:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "    loop_end = timer()\n",
        "    time_loop = loop_end - loop_start\n",
        "    if verbose:\n",
        "        print(f'Time for {num_epochs} epochs (s): {(time_loop):.3f}')\n",
        "\n",
        "    return {'loss_values': losses_values,\n",
        "            'train_acc_values': train_acc_values,\n",
        "            'val_acc_values': val_acc_values,\n",
        "            'time': time_loop}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI2hH1UHG_iE"
      },
      "outputs": [],
      "source": [
        "def execute(name_train: str, network: nn.Module, starting_lr: float,\n",
        "            num_epochs: int,\n",
        "            data_loader_train: torch.utils.data.DataLoader,\n",
        "            data_loader_val: torch.utils.data.DataLoader) -> None:\n",
        "    \"\"\"Executes the training loop.\n",
        "\n",
        "    Args:\n",
        "        name_train: the name for the log subfolder.\n",
        "        network: the network to train.\n",
        "        starting_lr: the staring learning rate.\n",
        "        num_epochs: the number of epochs.\n",
        "        data_loader_train: the data loader with training data.\n",
        "        data_loader_val: the data loader with validation data.\n",
        "    \"\"\"\n",
        "    # Visualization\n",
        "    log_interval = 20\n",
        "    log_dir = os.path.join(\"logs\", name_train)\n",
        "    writer = torch.utils.tensorboard.writer.SummaryWriter(log_dir)\n",
        "\n",
        "    # Optimization\n",
        "    optimizer = optim.SGD(network.parameters(), lr=starting_lr, momentum=0.9,\n",
        "                          weight_decay=0.0001)\n",
        "    \n",
        "    # Learning Rate schedule: decays the learning rate by a factor of `gamma`\n",
        "    # every `step_size` epochs\n",
        "    scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "    # With newer optimizer such as Adam or AdamW the learning rate scheduler\n",
        "    # is no longer needed, as each parameter has its own learning rate update\n",
        "    # that can vary from 0 (no update) to lambda (maximum update).\n",
        "    # optimizer = optim.AdamW(network.parameters(), lr=starting_lr)\n",
        "\n",
        "    statistics = training_loop(writer, num_epochs, optimizer, scheduler,\n",
        "                               log_interval, network, data_loader_train,\n",
        "                               data_loader_val)\n",
        "    writer.close()\n",
        "\n",
        "    best_epoch = np.argmax(statistics['val_acc_values']) + 1\n",
        "    best_accuracy = statistics['val_acc_values'][best_epoch - 1]\n",
        "\n",
        "    print(f'Best val accuracy: {best_accuracy:.2f} epoch: {best_epoch}.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7FiovxiJjDb"
      },
      "source": [
        "## Train the network from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqfBQzCmeuwn"
      },
      "source": [
        "To build our classifier we can use one of the off-the-shelf models provided in the [model zoo](https://pytorch.org/serve/model_zoo.html) of PyTorch. In this case, we will rely on a [ResNet18](https://pytorch.org/docs/stable/_modules/torchvision/models/resnet.html#resnet18). In this first example we will train the network from scratch. We have to set the parameter ```num_classes``` in the constructor of `models.resnet18` equal to the number of classes in our dataset (ie 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rURb-4P-qm2",
        "outputId": "4454d680-3502-4235-ac83-1f4c916346ae"
      },
      "outputs": [],
      "source": [
        "# Deprecated since version 0.13 of torchvision, may be removed in the future.\n",
        "# net_from_scratch = models.resnet18(pretrained=False, num_classes=num_classes)\n",
        "\n",
        "# Correct way\n",
        "net_from_scratch = models.resnet18(weights=None, num_classes=num_classes)\n",
        "net_from_scratch.to(device)\n",
        "\n",
        "# You can use the batch size to preview the total memory impact of the model\n",
        "# during forward and backward pass.\n",
        "summary(net_from_scratch,input_size=(size_batch, 3, size_image, size_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpDw_Wd7KuRi"
      },
      "source": [
        "We can use similar hyperparameters to those used in the [paper](https://arxiv.org/pdf/1512.03385.pdf).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t5I1o-K12Cb",
        "outputId": "6342e650-1190-4878-9d27-6c2b65f3103b"
      },
      "outputs": [],
      "source": [
        "name_train = \"resnet_from_scratch\"\n",
        "lr = 0.001\n",
        "num_epochs = 20  # try a higher number\n",
        "execute(name_train, net_from_scratch, lr, num_epochs, loader_train, loader_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2rxUhlWSruO"
      },
      "source": [
        "## Transfer Learning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVDJpvd2el6G"
      },
      "source": [
        "Due to the too small size of our train dataset the solution learned from the network is not very accurate. This is the case in which transfer learning can help us. We can use the feature extractor trained on the ImageNet dataset as plug-and-play module and add a new classifier.\n",
        "\n",
        "PyTorch [implementation](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py#L173) of [ResNet18](https://pytorch.org/hub/pytorch_vision_resnet/).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgsXl6XL5Tdh"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import ResNet18_Weights\n",
        "\n",
        "def get_model(pretrained: bool, num_classes: int) -> nn.Module:\n",
        "    \"\"\"Gets a image classifier based on ResNet18.\n",
        "\n",
        "    Args:\n",
        "        pretrained: if true initializes the network with ImageNet weights.\n",
        "        num_classes: the number of classes.\n",
        "\n",
        "    Returns:\n",
        "        The required network.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "    # Here we override the old classifier\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ahj4KKc5YBPY"
      },
      "source": [
        "To avoid to use the gradients with respect to some parameters of our model, we can set the attribute `requires_grad` to `False` as explained in the [autograd](https://pytorch.org/docs/stable/notes/autograd.html) page of PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J_536pNWTXc"
      },
      "outputs": [],
      "source": [
        "def set_requires_grad_for_layer(layer: torch.nn.Module, train: bool) -> None:\n",
        "    \"\"\"Sets the attribute requires_grad to True or False for each parameter.\n",
        "\n",
        "        Args:\n",
        "            layer: the layer to freeze.\n",
        "            train: if true train the layer.\n",
        "    \"\"\"\n",
        "    for p in layer.parameters():\n",
        "        p.requires_grad = train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4OuznVMS3OM",
        "outputId": "4e060b0d-2485-4f9f-d17a-97b829435e0d"
      },
      "outputs": [],
      "source": [
        "net_feat_ext = get_model(True, num_classes)\n",
        "net_feat_ext.to(device)\n",
        "\n",
        "set_requires_grad_for_layer(net_feat_ext.conv1, False)\n",
        "set_requires_grad_for_layer(net_feat_ext.bn1, False)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer1, False)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer2, False)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer3, False)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer4, False)\n",
        "\n",
        "summary(net_feat_ext, input_size=(size_batch, 3, size_image, size_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6h5iwP-Xb2Z",
        "outputId": "4efd1bf6-d448-4e74-a745-6265078994f7"
      },
      "outputs": [],
      "source": [
        "name_train = \"resnet_feat_ext\"\n",
        "execute(name_train, net_feat_ext, lr, num_epochs, loader_train, loader_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "z_BVUOUapBIR",
        "outputId": "98f23866-4faa-4553-9d0e-7e7c46531588"
      },
      "outputs": [],
      "source": [
        "index_sample = random.randint(0, len(data_val))\n",
        "image, label =  data_val[index_sample]\n",
        "batch_image = image.unsqueeze(0)\n",
        "\n",
        "net_feat_ext.eval()\n",
        "with torch.no_grad():\n",
        "    output = net_feat_ext(batch_image.to(device))\n",
        "    _, preds = torch.max(output, 1)\n",
        "\n",
        "fig = plt.figure()\n",
        "cax = plt.imshow(transforms.ToPILImage()(denormalize(image)))\n",
        "\n",
        "title = f'Prediction: {classes[preds[0].item()]} - Label: {classes[label]}'\n",
        "title_obj = plt.title(title)\n",
        "plt.setp(title_obj, color=(\"green\" if preds[0]==label else \"red\"))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yj2OdPJJQ9O"
      },
      "source": [
        "## Fine Tuning the Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xC82Sm4e1zc"
      },
      "source": [
        "Once the network has been trained on the new dataset, you can try to continue training for few epochs the whole model end-to-end on the new dataset using a lower learning rate. A common practice is to make the initial learning rate 10 times smaller than the one used to train the network from scratch.\n",
        "\n",
        "> **Good Practice**: *use a smaller learning rate than the one use for the scratch training*.\n",
        "\n",
        "> **Good Practice**: *fine-tune for few epochs*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR-oBJE66J8f"
      },
      "source": [
        "Check the trainable parameters for the froozen model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjsrrin05zTL",
        "outputId": "43e782bc-0d75-4a65-918c-68ba379d1215"
      },
      "outputs": [],
      "source": [
        "print(\"Trainable parameters: \", summary(net_feat_ext, input_size=(size_batch, 3, size_image, size_image)).trainable_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kChBUKh5KbWJ"
      },
      "outputs": [],
      "source": [
        "set_requires_grad_for_layer(net_feat_ext.conv1, True)\n",
        "set_requires_grad_for_layer(net_feat_ext.bn1, True)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer1, True)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer2, True)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer3, True)\n",
        "set_requires_grad_for_layer(net_feat_ext.layer4, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHADs8GIbvBI"
      },
      "source": [
        "Check the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s47oasibt-X",
        "outputId": "df3af0a4-7a1c-4b23-9554-8f094c2b3812"
      },
      "outputs": [],
      "source": [
        "print(\"Trainable parameters: \", summary(net_feat_ext, input_size=(size_batch, 3, size_image, size_image)).trainable_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAYjChp4Fvax",
        "outputId": "943c5fad-66a3-47db-fddf-f5932a832f9f"
      },
      "outputs": [],
      "source": [
        "name_train = \"resnet_fine_tuning\"\n",
        "lr_ft = lr * 0.1\n",
        "num_epochs_ft = 10\n",
        "execute(name_train, net_feat_ext, lr_ft, num_epochs_ft, loader_train, loader_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVM01KpeNO3R"
      },
      "source": [
        "## Visual Transformer (ViT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6Tn2vQSNQQw",
        "outputId": "ffc27a0f-5e46-4347-9796-6c9fd3ad6ea6"
      },
      "outputs": [],
      "source": [
        "# https://github.com/rwightman/pytorch-image-models\n",
        "! pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZRnD887Nwkf"
      },
      "outputs": [],
      "source": [
        "def train_only_classification_layer(model, classf_layer_name):\n",
        "  for name, param in model.named_parameters():\n",
        "    if classf_layer_name in name:\n",
        "      param.requires_grad = True\n",
        "    else:\n",
        "      param.requires_grad = False\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gqaXgtdNaBS",
        "outputId": "a743316b-b17d-469a-b86e-7cf6601e534f"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "vit_model_name = 'vit_tiny_patch16_224' # try changing \"tiny\" with \"small\", check results and number of params\n",
        "vit_model = timm.create_model(vit_model_name, pretrained=True)\n",
        "vit_model.head = torch.nn.Linear(in_features=vit_model.head.in_features, out_features=num_classes)\n",
        "vit_model = train_only_classification_layer(vit_model, classf_layer_name = \"head\").to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Uu4GdTtVkNS"
      },
      "source": [
        "Check the trainable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md5OQzwUNl-I",
        "outputId": "84d9c2a7-1055-428c-f711-12ce4d04e0e1"
      },
      "outputs": [],
      "source": [
        "summary(vit_model, input_size=(size_batch, 3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpoJwl9HPPsJ",
        "outputId": "99b58d1b-67c6-4b4f-e586-8ac04b2eae61"
      },
      "outputs": [],
      "source": [
        "name_train = vit_model_name+\"_feat_ext\"\n",
        "lr_ft = lr\n",
        "num_epochs_ft = 10\n",
        "execute(name_train, vit_model, lr_ft, num_epochs_ft, loader_train, loader_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icPon2ZNLywk"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1kKAGx0Snoj"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=\"logs\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
